import tkinter as tk
from tkinter import ttk, messagebox, filedialog
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
from matplotlib.figure import Figure
import seaborn as sns
import json
import os
import glob
import warnings
import threading
import time
from datetime import datetime, timedelta
import random
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import xgboost as xgb
import lightgbm as lgb
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.regularizers import l1_l2

try:
    import tkintermapview
except ImportError:
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ tkintermapview: pip install tkintermapview")

warnings.filterwarnings('ignore')


class Config:
    DATA_BASE_PATH = "agricultural_data"
    YIELD_DATA_PATH = os.path.join(DATA_BASE_PATH, "–£—Ä–æ–∂–∞–π–Ω–æ—Å—Ç—å.xlsx")
    CURRENCY_DATA_PATH = os.path.join(DATA_BASE_PATH, "–î–æ–ª–ª–∞—Ä –ø—Ä–∏–º–µ—Ä.xlsx")
    WEATHER_DATA_DIR = os.path.join(DATA_BASE_PATH, "weather_data")
    OIL_PRICE_DATA_PATH = os.path.join(DATA_BASE_PATH, "oil_prices.xlsx")
    MOSBIR_INDEX_DATA_PATH = os.path.join(DATA_BASE_PATH, "–ò–Ω–¥–µ–∫—Å –ú–æ—Å–ë–∏—Ä–∂–∏.xlsx")
    REGIONS_BORDERS_PATH = os.path.join(DATA_BASE_PATH, "regions_borders.json")

    MODEL_TYPES = {
        "LSTM": "lstm", "GRU": "gru", "Transformer": "transformer",
        "Ensemble": "ensemble", "XGBoost": "xgboost", "RandomForest": "random_forest"
    }

    FORECAST_PERIODS = {
        "1 –º–µ—Å—è—Ü": 1, "6 –º–µ—Å—è—Ü–µ–≤": 6, "1 –≥–æ–¥": 12,
        "2 –≥–æ–¥–∞": 24, "3 –≥–æ–¥–∞": 36, "5 –ª–µ—Ç": 60
    }

    CROPS = {
        "–ü—à–µ–Ω–∏—Ü–∞": "wheat", "–Ø—á–º–µ–Ω—å": "barley", "–†–æ–∂—å": "rye",
        "–û–≤–µ—Å": "oats", "–ö—É–∫—É—Ä—É–∑–∞": "corn", "–ü–æ–¥—Å–æ–ª–Ω–µ—á–Ω–∏–∫": "sunflower",
        "–°–æ—è": "soy", "–†–∞–ø—Å": "rapeseed"
    }

    COLORS = {
        "primary": "#2c3e50", "secondary": "#34495e", "accent": "#3498db",
        "success": "#27ae60", "warning": "#f39c12", "danger": "#e74c3c",
        "light": "#ecf0f1", "dark": "#2c3e50"
    }


class AgriculturalDataLoader:
    def __init__(self):
        self.yield_data = None
        self.weather_data = {}
        self.currency_data = {}
        self.oil_data = None
        self.mosbir_index_data = None
        self.region_coordinates = {}
        self.loaded = False
        self.region_weather_mapping = {}
        self.region_folders = {}

    def load_all_data(self):
        print("üîÑ –ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö...")
        try:
            os.makedirs(Config.DATA_BASE_PATH, exist_ok=True)
            os.makedirs(Config.WEATHER_DATA_DIR, exist_ok=True)

            self.load_yield_data()
            self.load_weather_data()
            self.load_currency_data()
            self.load_oil_price_data()
            self.load_mosbir_index_data()
            self.create_region_weather_mapping()

            self.loaded = True
            print("‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            self.loaded = False
            return False

    def load_yield_data(self):
        try:
            if os.path.exists(Config.YIELD_DATA_PATH):
                self.yield_data = pd.read_excel(Config.YIELD_DATA_PATH, sheet_name='–õ–∏—Å—Ç1', header=0)
                yield_data_long = []

                for idx, row in self.yield_data.iterrows():
                    region_name = str(row.iloc[0]).strip()
                    for col in self.yield_data.columns[1:]:
                        if str(col).isdigit():
                            year = int(col)
                            yield_value = row[col]
                            if pd.notna(yield_value) and yield_value != '':
                                yield_data_long.append({
                                    'region': region_name,
                                    'year': year,
                                    'yield': float(yield_value)
                                })

                self.yield_data = pd.DataFrame(yield_data_long)
                print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(self.yield_data)} –∑–∞–ø–∏—Å–µ–π")
                print(f"üìä –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–µ–≥–∏–æ–Ω—ã: {self.get_available_regions()}")
            else:
                raise FileNotFoundError(f"–§–∞–π–ª —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {Config.YIELD_DATA_PATH}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç–∏: {e}")
            raise

    def load_weather_data(self):
        try:
            weather_files = []
            for root, dirs, files in os.walk(Config.WEATHER_DATA_DIR):
                for file in files:
                    if file.endswith(('.xlsx', '.xls')):
                        weather_files.append(os.path.join(root, file))

            if not weather_files:
                print(f"‚ö†Ô∏è –§–∞–π–ª—ã –ø–æ–≥–æ–¥—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {Config.WEATHER_DATA_DIR}")
                return

            loaded_files = 0
            for file_path in weather_files:
                try:
                    filename = os.path.basename(file_path)
                    city_name = self.extract_city_name(filename)
                    if not city_name:
                        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞ –∏–∑ {filename}")
                        continue

                    folder_name = os.path.basename(os.path.dirname(file_path))
                    if folder_name == Config.WEATHER_DATA_DIR:
                        folder_name = "–û–±—â–∏–µ"

                    df = self.load_single_weather_file(file_path)
                    if df is not None and not df.empty:
                        key = f"{folder_name}_{city_name}"
                        self.weather_data[key] = df
                        self.region_folders[key] = folder_name
                        loaded_files += 1
                        print(f"‚úÖ –ü–æ–≥–æ–¥–∞ {folder_name}/{city_name}: {len(df)} –∑–∞–ø–∏—Å–µ–π")
                    else:
                        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ {filename}")
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ–≥–æ–¥—ã {file_path}: {e}")

            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø–æ–≥–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {loaded_files} —Ñ–∞–π–ª–æ–≤")
            if loaded_files == 0:
                print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –ø–æ–≥–æ–¥—ã, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –ø–æ–≥–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        except Exception as e:
            print(f"‚ùå –û–±—â–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ–≥–æ–¥—ã: {e}")

    def extract_city_name(self, filename):
        import re
        name = os.path.splitext(filename)[0]
        name = re.sub(r'\d{4}.*\d{4}', '', name)
        name = re.sub(r'\d+', '', name)
        name = name.replace('_', ' ').replace('-', ' ').strip()
        name = re.sub(r'\s+', ' ', name)
        return name if name else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π"

    def load_single_weather_file(self, file_path):
        try:
            print(f"üìñ –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞: {os.path.basename(file_path)}")

            sheets_to_try = ['–ê—Ä—Ö–∏–≤ –ü–æ–≥–æ–¥—ã rp5', '–õ–∏—Å—Ç1', 'Sheet1', 0]
            df = None

            for sheet in sheets_to_try:
                try:
                    df = pd.read_excel(file_path, sheet_name=sheet)
                    if df is not None and not df.empty:
                        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–Ω –ª–∏—Å—Ç: {sheet}")
                        break
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ª–∏—Å—Ç–∞ {sheet}: {e}")
                    continue

            if df is None or df.empty:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª {file_path}")
                return None

            print(f"üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö ({os.path.basename(file_path)}):")
            print(f"   –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
            print(f"   –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {len(df)}")
            if len(df) > 0:
                print(f"   –ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏:")
                print(df.head(2))

            df.columns = [str(col).lower().strip() for col in df.columns]
            print(f"üìù –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")

            df = self.process_dates(df)

            if df.empty:
                print(f"‚ö†Ô∏è –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞—Ç –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–µ–π –≤ —Ñ–∞–π–ª–µ {file_path}")
                return None

            print("üîÑ –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫...")

            rename_dict = {}

            column_mapping = {
                'temp': 'temperature',
                'davlenie': 'pressure',
                'vlaga': 'humidity',
                'date': 'date'
            }

            for old_name, new_name in column_mapping.items():
                if old_name in df.columns:
                    rename_dict[old_name] = new_name
                    print(f"   {old_name} -> {new_name}")

            if rename_dict:
                df = df.rename(columns=rename_dict)

            print(f"üìù –ö–æ–ª–æ–Ω–∫–∏ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è: {list(df.columns)}")

            available_columns = [col for col in ['temperature', 'pressure', 'humidity', 'date'] if col in df.columns]
            if not available_columns:
                print(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω—ã –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ñ–∞–π–ª–µ {file_path}")
                return None

            df = df[available_columns]

            for col in ['temperature', 'pressure', 'humidity']:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                    if col == 'temperature':
                        df[col] = df[col].apply(lambda x: x if -50 <= x <= 50 else np.nan)
                    elif col == 'pressure':
                        df[col] = df[col].apply(lambda x: x if 700 <= x <= 800 else np.nan)
                    elif col == 'humidity':
                        df[col] = df[col].apply(lambda x: x if 0 <= x <= 100 else np.nan)

            numeric_cols = [col for col in ['temperature', 'pressure', 'humidity'] if col in df.columns]
            if numeric_cols:
                initial_count = len(df)
                df = df.dropna(subset=numeric_cols, how='all')
                final_count = len(df)
                print(f"üìä –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö: {initial_count} -> {final_count} –∑–∞–ø–∏—Å–µ–π")

            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω —Ñ–∞–π–ª {os.path.basename(file_path)}: {len(df)} –∑–∞–ø–∏—Å–µ–π")
            return df

        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª {file_path}: {e}")
            import traceback
            print(f"üîç –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {traceback.format_exc()}")
            return None

    def process_dates(self, df):
        date_columns = [col for col in df.columns if any(x in col.lower() for x in ['date', 'data', '–≤—Ä–µ–º—è', '–¥–∞—Ç–∞'])]

        if not date_columns:
            for col in df.columns:
                if len(df) > 0:
                    sample_val = str(df[col].iloc[0])
                    if any(x in sample_val for x in ['202', '201', '200', '/', '-', ':']):
                        date_columns = [col]
                        break

        if not date_columns:
            print("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫—É —Å –¥–∞—Ç–∞–º–∏")
            return df

        date_col = date_columns[0]
        print(f"üìÖ –ò—Å–ø–æ–ª—å–∑—É—é –∫–æ–ª–æ–Ω–∫—É '{date_col}' –¥–ª—è –¥–∞—Ç")

        df[date_col] = df[date_col].astype(str).str.strip()

        sample_dates = df[date_col].head(3).tolist()
        print(f"üìÖ –ü—Ä–∏–º–µ—Ä—ã –¥–∞—Ç: {sample_dates}")

        def parse_custom_date(date_str):
            try:
                if ' ' in date_str:
                    date_part, time_part = date_str.split(' ', 1)
                    day, month, year = date_part.split('.')
                    hour, minute = time_part.split(':')
                    return pd.Timestamp(year=int(year), month=int(month), day=int(day),
                                        hour=int(hour), minute=int(minute))
                else:
                    day, month, year = date_str.split('.')
                    return pd.Timestamp(year=int(year), month=int(month), day=int(day))
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç—ã '{date_str}': {e}")
                return pd.NaT

        print("üîÑ –ü—Ä–∏–º–µ–Ω—è—é –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–∞—Ç...")
        df['date'] = df[date_col].apply(parse_custom_date)

        valid_dates = df['date'].notna().sum()
        print(f"‚úÖ –í–∞–ª–∏–¥–Ω—ã—Ö –¥–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {valid_dates} –∏–∑ {len(df)}")

        if valid_dates == 0:
            print("‚ö†Ô∏è –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –ø—Ä–æ–±—É—é —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –º–µ—Ç–æ–¥—ã...")

            date_formats = [
                '%d.%m.%Y %H:%M', '%d.%m.%Y %H:%M:%S', '%d.%m.%Y',
                '%Y-%m-%d %H:%M:%S', '%Y-%m-%d',
                '%d/%m/%Y %H:%M', '%d/%m/%Y',
                '%m/%d/%Y %H:%M', '%m/%d/%Y',
                '%d.%m.%Y %H.%M'
            ]

            for fmt in date_formats:
                try:
                    temp_dates = pd.to_datetime(df[date_col], format=fmt, errors='coerce')
                    valid_count = temp_dates.notna().sum()
                    print(f"  –§–æ—Ä–º–∞—Ç {fmt}: {valid_count} –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞—Ç")

                    if valid_count > 0:
                        df['date'] = temp_dates
                        break
                except Exception as e:
                    print(f"  –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ {fmt}: {e}")
                    continue

            if df['date'].isna().all():
                print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞—Ç—ã —Ñ–æ—Ä–º–∞—Ç–∞–º–∏, –ø—Ä–æ–±—É—é –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ...")
                df['date'] = pd.to_datetime(df[date_col], errors='coerce')

        initial_count = len(df)
        df = df.dropna(subset=['date'])
        final_count = len(df)
        print(f"üìä –î–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã: {initial_count} -> {final_count} –∑–∞–ø–∏—Å–µ–π")

        return df

    def load_currency_data(self):
        try:
            if os.path.exists(Config.CURRENCY_DATA_PATH):
                sheets_to_try = ['RC', '–õ–∏—Å—Ç1', 'Sheet1', 0]
                df = None

                for sheet in sheets_to_try:
                    try:
                        df = pd.read_excel(Config.CURRENCY_DATA_PATH, sheet_name=sheet)
                        if df is not None and not df.empty:
                            break
                    except:
                        continue

                if df is None:
                    raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –∫—É—Ä—Å–æ–≤")

                df.columns = [str(col).lower().strip() for col in df.columns]

                date_columns = [col for col in df.columns if any(x in col for x in ['date', 'data', '–¥–∞—Ç–∞'])]
                if date_columns:
                    df['date'] = pd.to_datetime(df[date_columns[0]], errors='coerce')

                rate_columns = [col for col in df.columns if any(x in col for x in ['curs', '–∫—É—Ä—Å', 'rate', 'usd'])]
                if rate_columns:
                    df['usd_rub'] = pd.to_numeric(df[rate_columns[0]], errors='coerce')

                df = df.dropna(subset=['date', 'usd_rub'])
                self.currency_data['USD_RUB'] = df
                print(f"‚úÖ –ö—É—Ä—Å—ã –≤–∞–ª—é—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(df)} –∑–∞–ø–∏—Å–µ–π")
            else:
                print(f"‚ö†Ô∏è –§–∞–π–ª –∫—É—Ä—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {Config.CURRENCY_DATA_PATH}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—É—Ä—Å–æ–≤: {e}")

    def load_oil_price_data(self):
        try:
            if os.path.exists(Config.OIL_PRICE_DATA_PATH):
                self.oil_data = pd.read_excel(Config.OIL_PRICE_DATA_PATH)
                print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ –Ω–µ—Ñ—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(self.oil_data)} –∑–∞–ø–∏—Å–µ–π")
            else:
                print("‚ö†Ô∏è –§–∞–π–ª –Ω–µ—Ñ—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö –ø–æ –Ω–µ—Ñ—Ç–∏")
                self.oil_data = pd.DataFrame()
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–µ—Ñ—Ç–∏: {e}")
            self.oil_data = pd.DataFrame()

    def load_mosbir_index_data(self):
        try:
            if os.path.exists(Config.MOSBIR_INDEX_DATA_PATH):
                sheets_to_try = ['–ü—Ä–æ—à–ª—ã–µ –¥–∞–Ω–Ω—ã–µ - –ò–Ω–¥–µ–∫—Å –ú–æ—Å–ë–∏—Ä–∂', '–õ–∏—Å—Ç1', 'Sheet1', 0]
                df = None

                for sheet in sheets_to_try:
                    try:
                        df = pd.read_excel(Config.MOSBIR_INDEX_DATA_PATH, sheet_name=sheet)
                        if df is not None and not df.empty:
                            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–Ω –ª–∏—Å—Ç: {sheet}")
                            break
                    except Exception as e:
                        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ª–∏—Å—Ç–∞ {sheet}: {e}")
                        continue

                if df is None:
                    raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –∏–Ω–¥–µ–∫—Å–∞ –ú–æ—Å–ë–∏—Ä–∂–∏")

                df.columns = [str(col).lower().strip() for col in df.columns]
                print(f"üìä –ö–æ–ª–æ–Ω–∫–∏ –∏–Ω–¥–µ–∫—Å–∞ –ú–æ—Å–ë–∏—Ä–∂–∏: {list(df.columns)}")
                print(f"üìä –ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–∞–Ω–Ω—ã—Ö:")
                print(df.head(3))

                date_columns = [col for col in df.columns if any(x in col for x in ['date', 'data', '–¥–∞—Ç–∞', '–≤—Ä–µ–º—è'])]
                if date_columns:
                    print(f"üìÖ –ù–∞–π–¥–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–∞–º–∏: {date_columns}")
                    for date_col in date_columns:
                        df['date'] = pd.to_datetime(df[date_col], errors='coerce')
                        valid_dates = df['date'].notna().sum()
                        print(f"  –ö–æ–ª–æ–Ω–∫–∞ '{date_col}': {valid_dates} –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞—Ç")
                        if valid_dates > 0:
                            break
                else:
                    print("‚ö†Ô∏è –Ø–≤–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ —Å –¥–∞—Ç–æ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–±—É—é –ø–µ—Ä–≤—É—é –∫–æ–ª–æ–Ω–∫—É")
                    df['date'] = pd.to_datetime(df.iloc[:, 0], errors='coerce')

                price_columns = [col for col in df.columns if
                                 any(x in col for x in ['—Ü–µ–Ω–∞', 'price', 'close', '–∏–Ω–¥–µ–∫—Å', 'index', '–∑–Ω–∞—á–µ–Ω–∏–µ'])]
                if price_columns:
                    print(f"üí∞ –ù–∞–π–¥–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ —Å —Ü–µ–Ω–∞–º–∏: {price_columns}")
                    price_col = price_columns[0]
                    print(f"üí∞ –ò—Å–ø–æ–ª—å–∑—É—é –∫–æ–ª–æ–Ω–∫—É: {price_col}")

                    sample_values = df[price_col].head(3).tolist()
                    print(f"üí∞ –ü—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π: {sample_values}")

                    price_series = df[price_col].astype(str)
                    price_series = price_series.str.replace(' ', '', regex=False)
                    price_series = price_series.str.replace(',', '.', regex=False)

                    def clean_number(x):
                        try:
                            parts = x.split('.')
                            if len(parts) > 2:
                                whole_part = ''.join(parts[:-1])
                                decimal_part = parts[-1]
                                return f"{whole_part}.{decimal_part}"
                            return x
                        except:
                            return x

                    price_series = price_series.apply(clean_number)
                    df['mosbir_index'] = pd.to_numeric(price_series, errors='coerce')

                    print(f"üí∞ –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –ø—Ä–∏–º–µ—Ä—ã: {df['mosbir_index'].head(3).tolist()}")
                else:
                    print("‚ö†Ô∏è –Ø–≤–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ —Å —Ü–µ–Ω–æ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–±—É—é –≤—Ç–æ—Ä—É—é –∫–æ–ª–æ–Ω–∫—É")
                    price_series = df.iloc[:, 1].astype(str)
                    price_series = price_series.str.replace(' ', '', regex=False)
                    price_series = price_series.str.replace(',', '.', regex=False)
                    df['mosbir_index'] = pd.to_numeric(price_series, errors='coerce')

                initial_count = len(df)
                df = df.dropna(subset=['date', 'mosbir_index'])
                final_count = len(df)

                self.mosbir_index_data = df
                print(f"‚úÖ –ò–Ω–¥–µ–∫—Å –ú–æ—Å–ë–∏—Ä–∂–∏ –∑–∞–≥—Ä—É–∂–µ–Ω: {final_count} –∑–∞–ø–∏—Å–µ–π (–±—ã–ª–æ {initial_count})")

                if not df.empty:
                    min_date = df['date'].min()
                    max_date = df['date'].max()
                    print(
                        f"üìÖ –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –∏–Ω–¥–µ–∫—Å–∞ –ú–æ—Å–ë–∏—Ä–∂–∏: {min_date.strftime('%d.%m.%Y')} - {max_date.strftime('%d.%m.%Y')}")
                    print(f"üìà –î–∏–∞–ø–∞–∑–æ–Ω –∑–Ω–∞—á–µ–Ω–∏–π: {df['mosbir_index'].min():.2f} - {df['mosbir_index'].max():.2f}")

                    df['year'] = df['date'].dt.year
                    yearly_stats = df.groupby('year')['mosbir_index'].agg(['count', 'min', 'max', 'mean']).round(2)
                    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≥–æ–¥–∞–º:\n{yearly_stats}")
                else:
                    print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–∞ –ú–æ—Å–ë–∏—Ä–∂–∏ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏")

                    print("üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º:")
                    print(f"   –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {initial_count}")
                    print(f"   –ü—É—Å—Ç—ã—Ö –¥–∞—Ç: {df['date'].isna().sum()}")
                    print(f"   –ü—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏–Ω–¥–µ–∫—Å–∞: {df['mosbir_index'].isna().sum()}")
            else:
                print(f"‚ö†Ô∏è –§–∞–π–ª –∏–Ω–¥–µ–∫—Å–∞ –ú–æ—Å–ë–∏—Ä–∂–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {Config.MOSBIR_INDEX_DATA_PATH}")
                self.mosbir_index_data = pd.DataFrame()
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–Ω–¥–µ–∫—Å–∞ –ú–æ—Å–ë–∏—Ä–∂–∏: {e}")
            import traceback
            print(f"üîç –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {traceback.format_exc()}")
            self.mosbir_index_data = pd.DataFrame()

    def create_region_weather_mapping(self):
        available_regions = [str(region).strip() for region in self.yield_data['region'].unique()]

        print("üîó –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ä–µ–≥–∏–æ–Ω–æ–≤ –∏ –ø–æ–≥–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")

        for region in available_regions:
            region_lower = region.lower().strip()
            matching_weather_keys = []

            for weather_key, folder_name in self.region_folders.items():
                folder_lower = folder_name.lower()

                if (region_lower in folder_lower or
                        folder_lower in region_lower or
                        self.regions_similar(region_lower, folder_lower)):
                    matching_weather_keys.append(weather_key)

            if not matching_weather_keys:
                for weather_key in self.weather_data.keys():
                    city_part = weather_key.split('_')[-1].lower()
                    region_clean = self.clean_region_name(region_lower)

                    if (city_part in region_clean or
                            region_clean in city_part or
                            self.regions_similar(region_clean, city_part)):
                        matching_weather_keys.append(weather_key)

            if matching_weather_keys:
                selected_weather = matching_weather_keys[0]
                self.region_weather_mapping[region] = selected_weather
                print(f"‚úÖ –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ: {region} -> {selected_weather}")
            else:
                for weather_key in self.weather_data.keys():
                    if any(word in region_lower for word in weather_key.lower().split('_')):
                        matching_weather_keys.append(weather_key)
                        break

                if matching_weather_keys:
                    selected_weather = matching_weather_keys[0]
                    self.region_weather_mapping[region] = selected_weather
                    print(f"üîó –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ: {region} -> {selected_weather}")
                else:
                    print(f"‚ùå –ù–µ—Ç –ø–æ–≥–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞: {region}")

        print(f"‚úÖ –°–æ–∑–¥–∞–Ω mapping —Ä–µ–≥–∏–æ–Ω–æ–≤ –∏ –ø–æ–≥–æ–¥–Ω—ã—Ö —Å—Ç–∞–Ω—Ü–∏–π: {len(self.region_weather_mapping)} —Ä–µ–≥–∏–æ–Ω–æ–≤")

    def clean_region_name(self, region_name):
        common_words = ['–æ–±–ª–∞—Å—Ç—å', '–∫—Ä–∞–π', '—Ä–µ—Å–ø—É–±–ª–∏–∫–∞', '–∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π', '–æ–∫—Ä—É–≥', '–≥–æ—Ä–æ–¥']
        words = region_name.split()
        cleaned = [word for word in words if word not in common_words]
        return ' '.join(cleaned)

    def regions_similar(self, region1, region2):
        r1_clean = self.clean_region_name(region1)
        r2_clean = self.clean_region_name(region2)

        return (r1_clean in r2_clean or r2_clean in r1_clean or
                r1_clean.replace(' ', '') in r2_clean.replace(' ', '') or
                r2_clean.replace(' ', '') in r1_clean.replace(' ', ''))

    def get_region_data(self, region_name):
        if not self.loaded:
            return None

        normalized_region = str(region_name).strip()
        region_yield = self.yield_data[self.yield_data['region'] == normalized_region]

        if region_yield.empty:
            print(f"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç–∏ –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞: {normalized_region}")
            return None

        weather_key = self.region_weather_mapping.get(normalized_region)
        weather_data = self.weather_data.get(weather_key) if weather_key else None

        return {
            'yield': region_yield,
            'weather': weather_data,
            'currency': self.currency_data.get('USD_RUB'),
            'oil': self.oil_data,
            'mosbir_index': self.mosbir_index_data,
            'weather_city': weather_key
        }

    def get_available_regions(self):
        if self.yield_data is not None:
            return [str(region).strip() for region in self.yield_data['region'].unique().tolist()]
        return []


class AdvancedYieldPredictor:
    def __init__(self, model_type='ensemble'):
        self.model_type = model_type
        self.models = {}
        self.scalers = {}
        self.is_trained = False
        self.training_history = []
        self.feature_importance = {}
        self.feature_names = []
        self.expected_features = []
        self.lookback_period = 5
        self.all_possible_features = self.get_all_possible_features()

    def get_all_possible_features(self):
        features = [
            'avg_temperature', 'max_temperature', 'min_temperature',
            'temp_amplitude', 'temp_std',
            'spring_avg_temp', 'spring_max_temp',
            'summer_avg_temp', 'summer_max_temp',
            'autumn_avg_temp', 'growing_season_avg_temp',
            'avg_pressure', 'pressure_std', 'min_pressure', 'max_pressure',
            'avg_humidity', 'humidity_std', 'min_humidity', 'max_humidity',
            'spring_avg_humidity', 'summer_avg_humidity',
            'avg_usd_rate', 'usd_volatility', 'min_usd_rate', 'max_usd_rate',
            'avg_oil_price', 'oil_price_volatility',
            'avg_mosbir_index', 'mosbir_volatility', 'min_mosbir_index', 'max_mosbir_index',
            'mosbir_trend', 'mosbir_annual_return',
            'yield_trend', 'yield_std'
        ]

        for i in range(1, self.lookback_period + 1):
            features.append(f'yield_lag_{i}')

        return features

    def prepare_features(self, region_data, lookback_period=None):
        if lookback_period is None:
            lookback_period = self.lookback_period

        if region_data is None:
            return None, None
        yield_data = region_data['yield']
        weather_data = region_data['weather']
        currency_data = region_data['currency']
        oil_data = region_data['oil']
        mosbir_index_data = region_data['mosbir_index']

        if yield_data.empty:
            return None, None

        combined_data = []
        for _, row in yield_data.iterrows():
            year = row['year']
            yield_value = row['yield']
            features = self.extract_features_for_year(year, weather_data, currency_data, oil_data, mosbir_index_data,
                                                      yield_data, lookback_period)
            if features:
                features['target'] = yield_value
                combined_data.append(features)

        if not combined_data:
            return None, None

        feature_df = pd.DataFrame(combined_data)

        feature_df = feature_df.fillna(0)

        for feature in self.all_possible_features:
            if feature not in feature_df.columns:
                feature_df[feature] = 0.0

        if hasattr(self, 'expected_features') and self.expected_features:
            expected_cols = [col for col in self.expected_features if col in feature_df.columns]
            if 'target' in feature_df.columns:
                expected_cols.append('target')
            feature_df = feature_df[expected_cols]
        else:
            self.expected_features = [col for col in self.all_possible_features if col in feature_df.columns]

        self.feature_names = [col for col in feature_df.columns if col != 'target']
        X = feature_df[self.feature_names]
        y = feature_df['target'] if 'target' in feature_df.columns else None

        return X, y

    def extract_features_for_year(self, year, weather, currency, oil, mosbir_index, yield_history, lookback):
        features = {}
        try:
            for feature in self.all_possible_features:
                features[feature] = 0.0

            if weather is not None and not weather.empty:
                year_weather = weather[weather['date'].dt.year == year]
                if not year_weather.empty:
                    spring = year_weather[year_weather['date'].dt.month.isin([3, 4, 5])]
                    summer = year_weather[year_weather['date'].dt.month.isin([6, 7, 8])]
                    autumn = year_weather[year_weather['date'].dt.month.isin([9, 10, 11])]

                    if 'temperature' in year_weather.columns:
                        features['avg_temperature'] = year_weather['temperature'].mean()
                        features['max_temperature'] = year_weather['temperature'].max()
                        features['min_temperature'] = year_weather['temperature'].min()
                        features['temp_amplitude'] = features['max_temperature'] - features['min_temperature']
                        features['temp_std'] = year_weather['temperature'].std()

                        if not spring.empty:
                            features['spring_avg_temp'] = spring['temperature'].mean()
                            features['spring_max_temp'] = spring['temperature'].max()
                        if not summer.empty:
                            features['summer_avg_temp'] = summer['temperature'].mean()
                            features['summer_max_temp'] = summer['temperature'].max()
                        if not autumn.empty:
                            features['autumn_avg_temp'] = autumn['temperature'].mean()

                        growing_season = year_weather[year_weather['date'].dt.month.isin([4, 5, 6, 7, 8, 9])]
                        if not growing_season.empty:
                            features['growing_season_avg_temp'] = growing_season['temperature'].mean()

                    if 'pressure' in year_weather.columns:
                        features['avg_pressure'] = year_weather['pressure'].mean()
                        features['pressure_std'] = year_weather['pressure'].std()
                        features['min_pressure'] = year_weather['pressure'].min()
                        features['max_pressure'] = year_weather['pressure'].max()

                    if 'humidity' in year_weather.columns:
                        features['avg_humidity'] = year_weather['humidity'].mean()
                        features['humidity_std'] = year_weather['humidity'].std()
                        features['min_humidity'] = year_weather['humidity'].min()
                        features['max_humidity'] = year_weather['humidity'].max()

                        if not summer.empty:
                            features['summer_avg_humidity'] = summer['humidity'].mean()
                        if not spring.empty:
                            features['spring_avg_humidity'] = spring['humidity'].mean()

            if currency is not None and not currency.empty:
                year_currency = currency[currency['date'].dt.year == year]
                if not year_currency.empty and 'usd_rub' in year_currency.columns:
                    features['avg_usd_rate'] = year_currency['usd_rub'].mean()
                    features['usd_volatility'] = year_currency['usd_rub'].std()
                    features['min_usd_rate'] = year_currency['usd_rub'].min()
                    features['max_usd_rate'] = year_currency['usd_rub'].max()

            if mosbir_index is not None and not mosbir_index.empty:
                year_mosbir = mosbir_index[mosbir_index['date'].dt.year == year]
                if not year_mosbir.empty and 'mosbir_index' in year_mosbir.columns:
                    features['avg_mosbir_index'] = year_mosbir['mosbir_index'].mean()
                    features['mosbir_volatility'] = year_mosbir['mosbir_index'].std()
                    features['min_mosbir_index'] = year_mosbir['mosbir_index'].min()
                    features['max_mosbir_index'] = year_mosbir['mosbir_index'].max()

                    if len(year_mosbir) > 1:
                        dates_numeric = (year_mosbir['date'] - year_mosbir['date'].min()).dt.days
                        if dates_numeric.std() > 0:
                            trend_coeff = np.polyfit(dates_numeric, year_mosbir['mosbir_index'], 1)[0]
                            features['mosbir_trend'] = trend_coeff

                    if len(year_mosbir) >= 2:
                        first_value = year_mosbir.sort_values('date')['mosbir_index'].iloc[0]
                        last_value = year_mosbir.sort_values('date')['mosbir_index'].iloc[-1]
                        if first_value > 0:
                            features['mosbir_annual_return'] = (last_value - first_value) / first_value * 100

            for i in range(1, self.lookback_period + 1):
                prev_year = year - i
                prev_yield_data = yield_history[yield_history['year'] == prev_year]
                if not prev_yield_data.empty:
                    features[f'yield_lag_{i}'] = prev_yield_data['yield'].iloc[0]

            recent_years = [year - i for i in range(1, min(6, self.lookback_period + 1))]
            recent_yields = []
            for y in recent_years:
                yield_val = yield_history[yield_history['year'] == y]['yield']
                if not yield_val.empty:
                    recent_yields.append(yield_val.iloc[0])

            if len(recent_yields) > 1:
                features['yield_trend'] = np.polyfit(range(len(recent_yields)), recent_yields, 1)[0]
                features['yield_std'] = np.std(recent_yields)

            if oil is not None and not oil.empty:
                year_oil = oil[oil['date'].dt.year == year]
                if not year_oil.empty and 'oil_price' in year_oil.columns:
                    features['avg_oil_price'] = year_oil['oil_price'].mean()
                    features['oil_price_volatility'] = year_oil['oil_price'].std()

            for key in features:
                if pd.isna(features[key]):
                    features[key] = 0

            return features
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {year}: {e}")
            import traceback
            print(f"üîç –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {traceback.format_exc()}")
            return features

    def train_models(self, X, y):
        if X is None or y is None or len(X) < 8:
            print("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return False

        try:
            self.expected_features = X.columns.tolist()

            non_constant_features = X.columns[X.std() > 0].tolist()
            if len(non_constant_features) < len(X.columns):
                print(f"–£–¥–∞–ª–µ–Ω—ã –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {set(X.columns) - set(non_constant_features)}")
                X = X[non_constant_features]

            self.feature_names = X.columns.tolist()
            self.expected_features = self.feature_names

            self.scalers['feature'] = StandardScaler()
            X_scaled = self.scalers['feature'].fit_transform(X)
            self.scalers['target'] = StandardScaler()
            y_scaled = self.scalers['target'].fit_transform(y.values.reshape(-1, 1)).flatten()

            X_train, X_test, y_train, y_test = train_test_split(
                X_scaled, y_scaled, test_size=0.15, random_state=42, shuffle=False
            )

            model_performance = {}

            models_to_train = {
                'random_forest': RandomForestRegressor(n_estimators=200, max_depth=8, min_samples_split=3, random_state=42),
                'xgboost': xgb.XGBRegressor(n_estimators=150, max_depth=4, learning_rate=0.05, random_state=42),
                'gradient_boosting': GradientBoostingRegressor(n_estimators=150, max_depth=4, random_state=42)
            }

            for name, model in models_to_train.items():
                try:
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    score = r2_score(y_test, y_pred)
                    mae = mean_absolute_error(y_test, y_pred)
                    model_performance[name] = {'r2': score, 'mae': mae}
                    self.models[name] = model
                    print(f"‚úÖ –ú–æ–¥–µ–ª—å {name} –æ–±—É—á–µ–Ω–∞, R¬≤: {score:.3f}, MAE: {mae:.3f}")
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è {name}: {e}")

            self.training_history.append({
                'timestamp': pd.Timestamp.now(),
                'models_trained': list(self.models.keys()),
                'performance': model_performance,
                'best_model': max(model_performance, key=lambda x: model_performance[x]['r2']) if model_performance else None
            })

            self.is_trained = True
            print(f"‚úÖ –ú–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã. –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {self.training_history[-1]['best_model']}")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
            return False

    def predict(self, X, method='ensemble'):
        if not self.is_trained or X is None or len(self.models) == 0:
            return None, 0.0, 0.0

        try:
            if hasattr(X, 'columns'):
                X_aligned = pd.DataFrame(columns=self.feature_names)

                for col in self.feature_names:
                    if col in X.columns:
                        X_aligned[col] = X[col]
                    else:
                        X_aligned[col] = 0.0

                X = X_aligned

            X_scaled = self.scalers['feature'].transform(X)
            predictions = []
            model_weights = {}

            for name, model in self.models.items():
                try:
                    pred = model.predict(X_scaled)
                    predictions.append(pred)
                    if self.training_history and 'performance' in self.training_history[-1]:
                        perf = self.training_history[-1]['performance'].get(name, {'r2': 0.5})['r2']
                        model_weights[name] = max(0.1, perf)
                    else:
                        model_weights[name] = 0.5
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª—å—é {name}: {e}")
                    continue

            if not predictions:
                return None, 0.0, 0.0

            if method == 'ensemble' and len(predictions) > 1:
                total_weight = sum(model_weights.values())
                ensemble_pred = np.zeros_like(predictions[0])
                for i, pred in enumerate(predictions):
                    weight = list(model_weights.values())[i] / total_weight
                    ensemble_pred += pred * weight
                final_prediction_scaled = ensemble_pred
            else:
                final_prediction_scaled = predictions[0]

            final_prediction = self.scalers['target'].inverse_transform(
                final_prediction_scaled.reshape(-1, 1)
            ).flatten()[0]

            confidence = min(0.85, max(0.5, sum(model_weights.values()) / len(model_weights)))
            deviation = abs(final_prediction * 0.08)

            return final_prediction, confidence, deviation
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            import traceback
            print(f"üîç –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {traceback.format_exc()}")
            return None, 0.0, 0.0

    def calculate_feature_importance(self, X, feature_names):
        if 'random_forest' in self.models:
            try:
                rf_model = self.models['random_forest']
                importance = rf_model.feature_importances_
                self.feature_importance = dict(zip(feature_names, importance))
                self.feature_importance = dict(
                    sorted(self.feature_importance.items(), key=lambda x: x[1], reverse=True))
                return self.feature_importance
            except:
                pass
        return {}

    def get_model_performance(self):
        if self.training_history:
            return self.training_history[-1]['performance']
        return {}


class MapHandler:
    def __init__(self, parent_frame):
        self.parent_frame = parent_frame
        self.map_widget = None
        self.regions_data = {}
        self.loaded_regions = {}
        self.active_polygons = []
        self.active_markers = []
        self.current_marker = None
        self.current_highlighted_region = None
        self.setup_map()

    def setup_map(self):
        self.map_widget = tkintermapview.TkinterMapView(self.parent_frame, width=1200, height=600)
        self.map_widget.pack(fill=tk.BOTH, expand=True)
        self.map_widget.set_position(55.7558, 37.6173)
        self.map_widget.set_zoom(4)
        self.map_widget.set_tile_server("https://a.tile.openstreetmap.org/{z}/{x}/{y}.png")

    def load_regions_data(self, filename=None):
        if filename is None:
            filename = Config.REGIONS_BORDERS_PATH

        if os.path.exists(filename):
            try:
                with open(filename, 'r', encoding='utf-8') as f:
                    self.regions_data = json.load(f)

                self.loaded_regions = {}
                for region_name, region_data in self.regions_data.items():
                    if isinstance(region_data, dict):
                        if "0" in region_data:
                            coords = region_data["0"]
                            if coords and len(coords) > 0 and isinstance(coords[0], list) and len(coords[0]) == 2:
                                self.loaded_regions[region_name] = coords
                        elif "coordinates" in region_data:
                            coords = region_data["coordinates"]
                            if isinstance(coords, list) and len(coords) > 0:
                                if isinstance(coords[0][0], list):
                                    self.loaded_regions[region_name] = coords[0]
                                else:
                                    self.loaded_regions[region_name] = coords
                    elif isinstance(region_data, list):
                        if len(region_data) > 0 and isinstance(region_data[0], list):
                            self.loaded_regions[region_name] = region_data

                print(f"‚úÖ –ì—Ä–∞–Ω–∏—Ü—ã —Ä–µ–≥–∏–æ–Ω–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(self.loaded_regions)} —Ä–µ–≥–∏–æ–Ω–æ–≤")
                return len(self.loaded_regions)

            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≥—Ä–∞–Ω–∏—Ü —Ä–µ–≥–∏–æ–Ω–æ–≤: {e}")
                self.create_basic_regions()
                return len(self.loaded_regions)
        else:
            print("‚ö†Ô∏è –§–∞–π–ª –≥—Ä–∞–Ω–∏—Ü –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞—é –±–∞–∑–æ–≤—ã–µ —Ä–µ–≥–∏–æ–Ω—ã...")
            self.create_basic_regions()
            return len(self.loaded_regions)

    def create_basic_regions(self):
        basic_regions = {
            "–†–æ—Å—Ç–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å": [
                [47.222, 39.718], [48.0, 40.0], [48.5, 41.0], [47.5, 42.0],
                [46.0, 41.5], [45.5, 40.0], [46.0, 39.0], [47.222, 39.718]
            ],
            "–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä—Å–∫–∏–π –∫—Ä–∞–π": [
                [45.035, 38.975], [46.0, 39.5], [47.0, 39.0], [47.5, 38.0],
                [46.5, 37.0], [45.0, 37.5], [44.5, 38.0], [45.035, 38.975]
            ],
            "–°—Ç–∞–≤—Ä–æ–ø–æ–ª—å—Å–∫–∏–π –∫—Ä–∞–π": [
                [45.043, 41.969], [46.0, 42.5], [47.0, 42.0], [47.5, 41.0],
                [46.5, 40.0], [45.5, 40.5], [44.5, 41.0], [45.043, 41.969]
            ]
        }
        self.loaded_regions = basic_regions

    def show_region_borders(self, region_name=None):
        self.clear_map()

        if not self.loaded_regions:
            print("‚ö†Ô∏è –ù–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –≥—Ä–∞–Ω–∏—Ü —Ä–µ–≥–∏–æ–Ω–æ–≤")
            return

        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD', '#98D8C8']

        for i, (name, coordinates) in enumerate(self.loaded_regions.items()):
            if region_name and name != region_name:
                continue

            color = colors[i % len(colors)]

            try:
                polygon = self.map_widget.set_polygon(
                    coordinates,
                    fill_color=color,
                    outline_color=color,
                    border_width=2,
                    name=name
                )
                self.active_polygons.append(polygon)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä–µ–≥–∏–æ–Ω–∞ {name}: {e}")

    def show_all_regions_borders(self):
        self.show_region_borders()

    def highlight_region(self, region_name):
        self.clear_map()

        if region_name in self.loaded_regions:
            coordinates = self.loaded_regions[region_name]
            try:
                polygon = self.map_widget.set_polygon(
                    coordinates,
                    fill_color="#3498db",
                    outline_color="#3498db",
                    border_width=3,
                    name=region_name
                )
                self.active_polygons.append(polygon)
                self.current_highlighted_region = region_name

                if coordinates:
                    avg_lat = sum(coord[0] for coord in coordinates) / len(coordinates)
                    avg_lon = sum(coord[1] for coord in coordinates) / len(coordinates)
                    self.map_widget.set_position(avg_lat, avg_lon)
                    self.map_widget.set_zoom(7)

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø–æ–¥—Å–≤–µ—Ç–∫–∏ —Ä–µ–≥–∏–æ–Ω–∞ {region_name}: {e}")
        else:
            print(f"‚ö†Ô∏è –†–µ–≥–∏–æ–Ω {region_name} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –≥—Ä–∞–Ω–∏—Ü–∞—Ö")

    def add_marker(self, lat, lon, text=""):
        if self.current_marker:
            try:
                self.current_marker.delete()
            except:
                pass

        try:
            self.current_marker = self.map_widget.set_marker(lat, lon, text=text)
            self.active_markers.append(self.current_marker)
            return self.current_marker
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –º–∞—Ä–∫–µ—Ä–∞: {e}")
            return None

    def clear_map(self):
        for polygon in self.active_polygons:
            try:
                polygon.delete()
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –ø–æ–ª–∏–≥–æ–Ω–∞: {e}")
        self.active_polygons.clear()

        for marker in self.active_markers:
            try:
                marker.delete()
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –º–∞—Ä–∫–µ—Ä–∞: {e}")
        self.active_markers.clear()

        if self.current_marker:
            try:
                self.current_marker.delete()
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ –º–∞—Ä–∫–µ—Ä–∞: {e}")
            self.current_marker = None

        self.current_highlighted_region = None

    def find_region_by_coords(self, lat, lon):
        if not self.loaded_regions:
            return self.find_region_by_coords_fallback(lat, lon)

        for region_name, coordinates in self.loaded_regions.items():
            if self.point_in_polygon(lat, lon, coordinates):
                return region_name

        return self.find_region_by_coords_fallback(lat, lon)

    def point_in_polygon(self, lat, lon, polygon):
        if not polygon or len(polygon) < 3:
            return False

        inside = False
        j = len(polygon) - 1

        for i in range(len(polygon)):
            xi, yi = polygon[i]
            xj, yj = polygon[j]

            if ((yi > lon) != (yj > lon)) and (lat < (xj - xi) * (lon - yi) / (yj - yi) + xi):
                inside = not inside
            j = i

        return inside

    def find_region_by_coords_fallback(self, lat, lon):
        region_centers = {
            "–†–æ—Å—Ç–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å": (47.222, 39.718), "–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä—Å–∫–∏–π –∫—Ä–∞–π": (45.035, 38.975),
            "–°—Ç–∞–≤—Ä–æ–ø–æ–ª—å—Å–∫–∏–π –∫—Ä–∞–π": (45.043, 41.969), "–í–æ—Ä–æ–Ω–µ–∂—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å": (51.672, 39.184),
            "–ë–µ–ª–≥–æ—Ä–æ–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å": (50.597, 36.588), "–ö—É—Ä—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å": (51.730, 36.193),
            "–û—Ä–ª–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å": (52.967, 36.069), "–¢–∞–º–±–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å": (52.721, 41.453),
            "–õ–∏–ø–µ—Ü–∫–∞—è –æ–±–ª–∞—Å—Ç—å": (52.608, 39.599), "–ú–æ—Å–∫–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å": (55.755, 37.617),
            "–õ–µ–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å": (59.939, 30.315), "–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å": (55.030, 82.920),
            "–ê–ª—Ç–∞–π—Å–∫–∏–π –∫—Ä–∞–π": (53.348, 83.776), "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –¢–∞—Ç–∞—Ä—Å—Ç–∞–Ω": (55.796, 49.108),
            "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ë–∞—à–∫–æ—Ä—Ç–æ—Å—Ç–∞–Ω": (54.735, 55.958)
        }

        min_distance = float('inf')
        closest_region = None

        for region, center in region_centers.items():
            distance = ((lat - center[0]) ** 2 + (lon - center[1]) ** 2) ** 0.5
            if distance < min_distance:
                min_distance = distance
                closest_region = region

        return closest_region if min_distance < 5 else None

    def set_click_handler(self, callback):
        try:
            if hasattr(self.map_widget, 'add_left_click_map_command'):
                self.map_widget.add_left_click_map_command(callback)
            else:
                self.map_widget.add_right_click_menu_command("–í—ã–±—Ä–∞—Ç—å —Ä–µ–≥–∏–æ–Ω", callback, pass_coords=True)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ –∫–ª–∏–∫–æ–≤: {e}")
            self.map_widget.canvas.bind("<Button-1>", lambda event: callback((event.x, event.y)))

    def center_on_russia(self):
        self.map_widget.set_position(65, 90)
        self.map_widget.set_zoom(3)


class PredictionDialog(tk.Toplevel):
    def __init__(self, parent, region_name, available_crops):
        super().__init__(parent)
        self.parent = parent
        self.region_name = region_name
        self.available_crops = available_crops
        self.result = None
        self.title(f"–ü—Ä–æ–≥–Ω–æ–∑ —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç–∏ - {region_name}")
        self.geometry("500x600")
        self.configure(bg=Config.COLORS['primary'])
        self.transient(parent)
        self.grab_set()
        self.create_widgets()

    def create_widgets(self):
        main_frame = ttk.Frame(self)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=20, pady=20)

        title_label = ttk.Label(main_frame, text=f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–æ–≥–Ω–æ–∑–∞\n{self.region_name}", font=("Arial", 14, "bold"),
                                justify=tk.CENTER)
        title_label.pack(pady=10)

        ttk.Label(main_frame, text="–°–µ–ª—å—Å–∫–æ—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω–∞—è –∫—É–ª—å—Ç—É—Ä–∞:", font=("Arial", 10, "bold")).pack(anchor=tk.W,
                                                                                                      pady=5)
        self.crop_var = tk.StringVar(value="–ü—à–µ–Ω–∏—Ü–∞")
        crop_combo = ttk.Combobox(main_frame, textvariable=self.crop_var, values=list(self.available_crops.keys()),
                                  state="readonly", font=("Arial", 10))
        crop_combo.pack(fill=tk.X, pady=5)

        ttk.Label(main_frame, text="–ü–µ—Ä–∏–æ–¥ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è:", font=("Arial", 10, "bold")).pack(anchor=tk.W, pady=5)
        self.period_var = tk.StringVar(value="1 –≥–æ–¥")
        period_combo = ttk.Combobox(main_frame, textvariable=self.period_var,
                                    values=list(Config.FORECAST_PERIODS.keys()), state="readonly", font=("Arial", 10))
        period_combo.pack(fill=tk.X, pady=5)

        ttk.Label(main_frame, text="–ú–æ–¥–µ–ª—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è:", font=("Arial", 10, "bold")).pack(anchor=tk.W, pady=5)
        self.model_var = tk.StringVar(value="Ensemble")
        model_combo = ttk.Combobox(main_frame, textvariable=self.model_var, values=list(Config.MODEL_TYPES.keys()),
                                   state="readonly", font=("Arial", 10))
        model_combo.pack(fill=tk.X, pady=5)

        params_frame = ttk.LabelFrame(main_frame, text="–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
        params_frame.pack(fill=tk.X, pady=10)

        self.weather_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(params_frame, text="–£—á–∏—Ç—ã–≤–∞—Ç—å –ø–æ–≥–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", variable=self.weather_var).pack(anchor=tk.W,
                                                                                                        pady=2)

        self.economic_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(params_frame, text="–£—á–∏—Ç—ã–≤–∞—Ç—å —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏", variable=self.economic_var).pack(
            anchor=tk.W, pady=2)

        self.historical_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(params_frame, text="–£—á–∏—Ç—ã–≤–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ", variable=self.historical_var).pack(
            anchor=tk.W, pady=2)

        advanced_frame = ttk.LabelFrame(main_frame, text="–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏")
        advanced_frame.pack(fill=tk.X, pady=10)

        ttk.Label(advanced_frame, text="–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–∏–æ–¥ (–ª–µ—Ç):").pack(anchor=tk.W, pady=2)
        self.history_var = tk.IntVar(value=5)
        history_spin = ttk.Spinbox(advanced_frame, from_=3, to=10, textvariable=self.history_var, width=10)
        history_spin.pack(anchor=tk.W, pady=2)

        btn_frame = ttk.Frame(main_frame)
        btn_frame.pack(pady=20)

        ttk.Button(btn_frame, text="–û—Ç–º–µ–Ω–∞", command=self.cancel).pack(side=tk.LEFT, padx=5)
        ttk.Button(btn_frame, text="–°–¥–µ–ª–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑", command=self.confirm).pack(side=tk.LEFT, padx=5)

    def cancel(self):
        self.result = None
        self.destroy()

    def confirm(self):
        self.result = {
            'crop': self.crop_var.get(),
            'period': self.period_var.get(),
            'model': self.model_var.get(),
            'weather': self.weather_var.get(),
            'economic': self.economic_var.get(),
            'historical': self.historical_var.get(),
            'history_years': self.history_var.get()
        }
        self.destroy()


class ResultsWindow(tk.Toplevel):
    def __init__(self, parent, region_name, prediction_data, historical_data, feature_importance):
        super().__init__(parent)
        self.parent = parent
        self.region_name = region_name
        self.prediction_data = prediction_data
        self.historical_data = historical_data
        self.feature_importance = feature_importance
        self.title(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∞ - {region_name}")
        self.geometry("1200x800")
        self.configure(bg=Config.COLORS['primary'])
        self.create_widgets()

    def create_widgets(self):
        notebook = ttk.Notebook(self)
        notebook.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        self.create_summary_tab(notebook)
        self.create_charts_tab(notebook)
        self.create_analysis_tab(notebook)
        self.create_export_tab(notebook)

    def create_summary_tab(self, notebook):
        summary_frame = ttk.Frame(notebook)
        notebook.add(summary_frame, text="–°–≤–æ–¥–∫–∞")

        main_info = ttk.LabelFrame(summary_frame, text="–û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
        main_info.pack(fill=tk.X, padx=10, pady=5)
        info_text = (f"–†–µ–≥–∏–æ–Ω: {self.region_name}\n–ö—É–ª—å—Ç—É—Ä–∞: {self.prediction_data['crop']}\n"
                     f"–ü–µ—Ä–∏–æ–¥ –ø—Ä–æ–≥–Ω–æ–∑–∞: {self.prediction_data['period']}\n–ú–æ–¥–µ–ª—å: {self.prediction_data['model']}\n"
                     f"–î–∞—Ç–∞ —Ä–∞—Å—á–µ—Ç–∞: {datetime.now().strftime('%d.%m.%Y %H:%M')}")
        ttk.Label(main_info, text=info_text, justify=tk.LEFT, font=("Arial", 10)).pack(padx=10, pady=10)

        metrics_frame = ttk.LabelFrame(summary_frame, text="–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏")
        metrics_frame.pack(fill=tk.X, padx=10, pady=5)
        metrics_text = (f"–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º–∞—è —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç—å: {self.prediction_data['predicted_yield']:.1f} —Ü/–≥–∞\n"
                        f"–ò–∑–º–µ–Ω–µ–Ω–∏–µ –∫ –ø—Ä–æ—à–ª–æ–º—É –≥–æ–¥—É: {self.prediction_data['change']:+.1f}%\n"
                        f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏: {self.prediction_data['confidence']:.1%}\n"
                        f"–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª: ¬±{self.prediction_data['deviation']:.1f} —Ü/–≥–∞")
        if 'model_quality' in self.prediction_data:
            metrics_text += f"\n–ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏: {self.prediction_data['model_quality']:.1%}"
        ttk.Label(metrics_frame, text=metrics_text, justify=tk.LEFT, font=("Arial", 10)).pack(padx=10, pady=10)

        recommendations_frame = ttk.LabelFrame(summary_frame, text="–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
        recommendations_frame.pack(fill=tk.X, padx=10, pady=5)
        recommendations = self.generate_recommendations()
        for rec in recommendations:
            ttk.Label(recommendations_frame, text=rec, justify=tk.LEFT).pack(anchor=tk.W, padx=10, pady=2)

    def create_charts_tab(self, notebook):
        charts_frame = ttk.Frame(notebook)
        notebook.add(charts_frame, text="–ì—Ä–∞—Ñ–∏–∫–∏")
        fig = Figure(figsize=(12, 8), dpi=100)
        ax1 = fig.add_subplot(221)
        self.plot_yield_trend(ax1)
        ax2 = fig.add_subplot(222)
        self.plot_year_comparison(ax2)
        ax3 = fig.add_subplot(223)
        self.plot_factors(ax3)
        ax4 = fig.add_subplot(224)
        self.plot_probability_distribution(ax4)
        fig.tight_layout()
        canvas = FigureCanvasTkAgg(fig, charts_frame)
        canvas.draw()
        canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)

    def create_analysis_tab(self, notebook):
        analysis_frame = ttk.Frame(notebook)
        notebook.add(analysis_frame, text="–ê–Ω–∞–ª–∏–∑")
        factors_frame = ttk.LabelFrame(analysis_frame, text="–ê–Ω–∞–ª–∏–∑ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –≤–ª–∏—è–Ω–∏—è")
        factors_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        text_widget = tk.Text(factors_frame, wrap=tk.WORD, width=80, height=20)
        scrollbar = ttk.Scrollbar(factors_frame, orient="vertical", command=text_widget.yview)
        text_widget.configure(yscrollcommand=scrollbar.set)
        text_widget.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5, pady=5)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y, pady=5)
        analysis_report = self.generate_analysis_report()
        text_widget.insert(tk.END, analysis_report)
        text_widget.config(state=tk.DISABLED)

    def create_export_tab(self, notebook):
        export_frame = ttk.Frame(notebook)
        notebook.add(export_frame, text="–≠–∫—Å–ø–æ—Ä—Ç")
        ttk.Label(export_frame, text="–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∞", font=("Arial", 12, "bold")).pack(pady=10)
        ttk.Button(export_frame, text="Excel —Ñ–∞–π–ª —Å –ø–æ–ª–Ω—ã–º –æ—Ç—á–µ—Ç–æ–º", command=self.export_to_excel).pack(pady=5)
        ttk.Button(export_frame, text="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏", command=self.export_charts).pack(pady=5)

    def plot_yield_trend(self, ax):
        if self.historical_data and 'years' in self.historical_data and 'yields' in self.historical_data:
            years = self.historical_data['years']
            yields = self.historical_data['yields']
            if len(years) > 0 and len(yields) > 0:
                ax.plot(years, yields, 'bo-', label='–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ', linewidth=2)
                if len(years) > 0:
                    last_year = years[-1]
                    ax.plot([last_year, last_year + 1], [yields[-1], self.prediction_data['predicted_yield']], 'ro--',
                            label='–ü—Ä–æ–≥–Ω–æ–∑', linewidth=2)
                    ax.fill_between([last_year + 1],
                                    self.prediction_data['predicted_yield'] - self.prediction_data['deviation'],
                                    self.prediction_data['predicted_yield'] + self.prediction_data['deviation'],
                                    alpha=0.3, color='red', label='–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª')
        ax.set_title('–î–∏–Ω–∞–º–∏–∫–∞ —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç–∏')
        ax.set_xlabel('–ì–æ–¥')
        ax.set_ylabel('–£—Ä–æ–∂–∞–π–Ω–æ—Å—Ç—å (—Ü/–≥–∞)')
        ax.legend()
        ax.grid(True, alpha=0.3)

    def plot_year_comparison(self, ax):
        if self.historical_data and 'yields' in self.historical_data and len(self.historical_data['yields']) > 0:
            categories = ['–ü—Ä–æ—à–ª—ã–π –≥–æ–¥', '–ü—Ä–æ–≥–Ω–æ–∑']
            values = [self.historical_data['yields'][-1], self.prediction_data['predicted_yield']]
            colors = [Config.COLORS['accent'], Config.COLORS['success']]
            bars = ax.bar(categories, values, color=colors, alpha=0.7)
            ax.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º –≥–æ–¥–æ–º')
            ax.set_ylabel('–£—Ä–æ–∂–∞–π–Ω–æ—Å—Ç—å (—Ü/–≥–∞)')
            for bar, value in zip(bars, values):
                ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5, f'{value:.1f}', ha='center',
                        va='bottom', fontweight='bold')
        else:
            ax.text(0.5, 0.5, '–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö\n–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è', ha='center', va='center', transform=ax.transAxes)

    def plot_factors(self, ax):
        if self.feature_importance:
            factors = list(self.feature_importance.keys())[:8]
            importance = list(self.feature_importance.values())[:8]
            y_pos = np.arange(len(factors))
            ax.barh(y_pos, importance, alpha=0.7, color=Config.COLORS['warning'])
            ax.set_yticks(y_pos)
            ax.set_yticklabels(factors)
            ax.set_title('–í–∞–∂–Ω–æ—Å—Ç—å —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –≤–ª–∏—è–Ω–∏—è')
            ax.set_xlabel('–í–∞–∂–Ω–æ—Å—Ç—å')
        else:
            ax.text(0.5, 0.5, '–î–∞–Ω–Ω—ã–µ –æ –≤–∞–∂–Ω–æ—Å—Ç–∏ —Ñ–∞–∫—Ç–æ—Ä–æ–≤\n–Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã', ha='center', va='center',
                    transform=ax.transAxes)

    def plot_probability_distribution(self, ax):
        mean = self.prediction_data['predicted_yield']
        std = self.prediction_data['deviation'] / 2
        x = np.linspace(max(0, mean - 3 * std), mean + 3 * std, 100)
        y = np.exp(-0.5 * ((x - mean) / std) ** 2) / (std * np.sqrt(2 * np.pi))
        ax.plot(x, y, 'g-', linewidth=2, label='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π')
        ax.fill_between(x, y, alpha=0.3, color='green')
        ax.axvline(mean, color='red', linestyle='--', label=f'–°—Ä–µ–¥–Ω–µ–µ: {mean:.1f}')
        ax.set_title('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞')
        ax.set_xlabel('–£—Ä–æ–∂–∞–π–Ω–æ—Å—Ç—å (—Ü/–≥–∞)')
        ax.set_ylabel('–ü–ª–æ—Ç–Ω–æ—Å—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏')
        ax.legend()
        ax.grid(True, alpha=0.3)

    def generate_recommendations(self):
        recommendations = []
        change = self.prediction_data['change']
        confidence = self.prediction_data['confidence']
        if change > 5:
            recommendations.append("‚Ä¢ –ë–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑")
            recommendations.append("‚Ä¢ –£–≤–µ–ª–∏—á–∏—Ç—å –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ –≤ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–µ–º–µ–Ω–∞")
        elif change < -5:
            recommendations.append("‚Ä¢ –°–Ω–∏–∂–µ–Ω–∏–µ —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç–∏ - –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –ø–ª–∞–Ω—ã")
            recommendations.append("‚Ä¢ –£–≤–µ–ª–∏—á–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ—Å–µ–≤–æ–≤")
        else:
            recommendations.append("‚Ä¢ –°—Ç–∞–±–∏–ª—å–Ω–∞—è —Å–∏—Ç—É–∞—Ü–∏—è - –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é")
        if confidence < 0.7:
            recommendations.append("‚Ä¢ –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∞ - —É—Å–∏–ª–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥")
        recommendations.append("‚Ä¢ –†–µ–≥—É–ª—è—Ä–Ω–æ –æ–±–Ω–æ–≤–ª—è—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤")
        recommendations.append("‚Ä¢ –°—Ä–∞–≤–Ω–∏–≤–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑—ã —Å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –º–æ–¥–µ–ª–µ–π")
        return recommendations

    def generate_analysis_report(self):
        report = "–î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–¢–ò–ß–ï–°–ö–ò–ô –û–¢–ß–ï–¢\n" + "=" * 50 + "\n\n"
        report += f"–†–ï–ì–ò–û–ù: {self.region_name}\n–ö–£–õ–¨–¢–£–†–ê: {self.prediction_data['crop']}\n"
        report += f"–ü–ï–†–ò–û–î –ü–†–û–ì–ù–û–ó–ê: {self.prediction_data['period']}\n–î–ê–¢–ê –ê–ù–ê–õ–ò–ó–ê: {datetime.now().strftime('%d.%m.%Y %H:%M')}\n\n"
        report += "–ö–õ–Æ–ß–ï–í–´–ï –ú–ï–¢–†–ò–ö–ò:\n"
        report += f"- –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º–∞—è —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç—å: {self.prediction_data['predicted_yield']:.1f} —Ü/–≥–∞\n"
        report += f"- –ò–∑–º–µ–Ω–µ–Ω–∏–µ –∫ –ø—Ä–æ—à–ª–æ–º—É –≥–æ–¥—É: {self.prediction_data['change']:+.1f}%\n"
        report += f"- –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏: {self.prediction_data['confidence']:.1%}\n"
        report += f"- –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª: ¬±{self.prediction_data['deviation']:.1f} —Ü/–≥–∞\n\n"
        report += "–ê–ù–ê–õ–ò–ó –§–ê–ö–¢–û–†–û–í –í–õ–ò–Ø–ù–ò–Ø:\n"
        if self.feature_importance:
            sorted_factors = sorted(self.feature_importance.items(), key=lambda x: x[1], reverse=True)
            for factor, importance in sorted_factors[:10]:
                report += f"- {factor}: {importance:.3f}\n"
        else:
            report += "–î–∞–Ω–Ω—ã–µ –æ –≤–∞–∂–Ω–æ—Å—Ç–∏ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã\n"
        report += "\n–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:\n"
        recommendations = self.generate_recommendations()
        for i, rec in enumerate(recommendations, 1):
            report += f"{i}. {rec}\n"
        return report

    def export_to_excel(self):
        filename = filedialog.asksaveasfilename(defaultextension=".xlsx",
                                                filetypes=[("Excel files", "*.xlsx"), ("All files", "*.*")],
                                                title="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á–µ—Ç –∫–∞–∫...")
        if filename:
            try:
                with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                    summary_data = {
                        '–ü–∞—Ä–∞–º–µ—Ç—Ä': ['–†–µ–≥–∏–æ–Ω', '–ö—É–ª—å—Ç—É—Ä–∞', '–ü–µ—Ä–∏–æ–¥ –ø—Ä–æ–≥–Ω–æ–∑–∞', '–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º–∞—è —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç—å (—Ü/–≥–∞)',
                                     '–ò–∑–º–µ–Ω–µ–Ω–∏–µ (%)', '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å (%)', '–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ (—Ü/–≥–∞)', '–ú–æ–¥–µ–ª—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è',
                                     '–î–∞—Ç–∞ —Ä–∞—Å—á–µ—Ç–∞'],
                        '–ó–Ω–∞—á–µ–Ω–∏–µ': [self.region_name, self.prediction_data['crop'], self.prediction_data['period'],
                                     f"{self.prediction_data['predicted_yield']:.2f}",
                                     f"{self.prediction_data['change']:+.2f}",
                                     f"{self.prediction_data['confidence'] * 100:.1f}",
                                     f"{self.prediction_data['deviation']:.2f}", self.prediction_data['model'],
                                     datetime.now().strftime('%d.%m.%Y %H:%M')]
                    }
                    pd.DataFrame(summary_data).to_excel(writer, sheet_name='–û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã', index=False)
                    if self.feature_importance:
                        factors_df = pd.DataFrame({'–§–∞–∫—Ç–æ—Ä': list(self.feature_importance.keys()),
                                                   '–í–∞–∂–Ω–æ—Å—Ç—å': list(self.feature_importance.values())}).sort_values(
                            '–í–∞–∂–Ω–æ—Å—Ç—å', ascending=False)
                        factors_df.to_excel(writer, sheet_name='–§–∞–∫—Ç–æ—Ä—ã –≤–ª–∏—è–Ω–∏—è', index=False)
                    if self.historical_data and 'years' in self.historical_data and 'yields' in self.historical_data:
                        history_df = pd.DataFrame(
                            {'–ì–æ–¥': self.historical_data['years'], '–£—Ä–æ–∂–∞–π–Ω–æ—Å—Ç—å': self.historical_data['yields']})
                        history_df.to_excel(writer, sheet_name='–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ', index=False)
                messagebox.showinfo("–£—Å–ø–µ—Ö", f"–û—Ç—á–µ—Ç —É—Å–ø–µ—à–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤:\n{filename}")
            except Exception as e:
                messagebox.showerror("–û—à–∏–±–∫–∞", f"–ù–µ —É–¥–∞–ª–æ—Å—å —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª:\n{str(e)}")

    def export_charts(self):
        try:
            fig = Figure(figsize=(12, 8), dpi=100)
            ax1 = fig.add_subplot(221)
            self.plot_yield_trend(ax1)
            ax2 = fig.add_subplot(222)
            self.plot_year_comparison(ax2)
            ax3 = fig.add_subplot(223)
            self.plot_factors(ax3)
            ax4 = fig.add_subplot(224)
            self.plot_probability_distribution(ax4)
            fig.tight_layout()
            filename = filedialog.asksaveasfilename(defaultextension=".png",
                                                    filetypes=[("PNG files", "*.png"), ("All files", "*.*")],
                                                    title="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏ –∫–∞–∫...")
            if filename:
                fig.savefig(filename, dpi=300, bbox_inches='tight')
                messagebox.showinfo("–£—Å–ø–µ—Ö", f"–ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤:\n{filename}")
        except Exception as e:
            messagebox.showerror("–û—à–∏–±–∫–∞", f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏:\n{str(e)}")


class AgriculturalPredictorApp:
    def __init__(self, root):
        self.root = root
        self.root.title("üåæ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç–∏")
        self.root.geometry("1400x900")
        self.root.configure(bg=Config.COLORS['primary'])

        self.status_var = tk.StringVar(value="–°–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è...")

        self.data_loader = AgriculturalDataLoader()
        self.predictor = AdvancedYieldPredictor()
        self.map_handler = None
        self.data_loaded = False
        self.model_trained = False
        self.current_region = None
        self.borders_loaded = False

        self.setup_styles()
        self.create_widgets()
        self.load_data_async()

    def setup_styles(self):
        style = ttk.Style()
        style.theme_use('clam')
        style.configure('TFrame', background=Config.COLORS['primary'])
        style.configure('TLabel', background=Config.COLORS['primary'], foreground='white')
        style.configure('TButton', background=Config.COLORS['accent'], foreground='white')
        style.configure('TLabelframe', background=Config.COLORS['secondary'], foreground='white')
        style.configure('TLabelframe.Label', background=Config.COLORS['secondary'], foreground='white')
        style.configure('TNotebook', background=Config.COLORS['primary'])
        style.configure('TNotebook.Tab', background=Config.COLORS['secondary'], foreground='white')

    def create_widgets(self):
        main_frame = ttk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        self.create_header(main_frame)
        self.create_control_panel(main_frame)
        self.create_main_content(main_frame)
        self.create_status_bar(main_frame)

    def create_header(self, parent):
        header_frame = ttk.Frame(parent)
        header_frame.pack(fill=tk.X, pady=(0, 10))
        title_label = tk.Label(header_frame, text="üåæ –ü–†–û–î–í–ò–ù–£–¢–ê–Ø –°–ò–°–¢–ï–ú–ê –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–Ø –£–†–û–ñ–ê–ô–ù–û–°–¢–ò",
                               font=("Arial", 18, "bold"), fg="white", bg=Config.COLORS['primary'])
        title_label.pack()
        subtitle_label = tk.Label(header_frame,
                                  text="–ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —É—á–µ—Ç–æ–º –ø–æ–≥–æ–¥–Ω—ã—Ö, —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏—Ö –∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤",
                                  font=("Arial", 10), fg="#bdc3c7", bg=Config.COLORS['primary'])
        subtitle_label.pack()

    def create_control_panel(self, parent):
        control_frame = ttk.LabelFrame(parent, text="–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–æ–π")
        control_frame.pack(fill=tk.X, pady=10)

        top_row = ttk.Frame(control_frame)
        top_row.pack(fill=tk.X, padx=10, pady=5)

        ttk.Button(top_row, text="üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ", command=self.load_data_dialog).pack(side=tk.LEFT, padx=5)
        ttk.Button(top_row, text="üó∫Ô∏è –ó–∞–≥—Ä—É–∑–∏—Ç—å –≥—Ä–∞–Ω–∏—Ü—ã", command=self.load_borders_dialog).pack(side=tk.LEFT, padx=5)
        ttk.Button(top_row, text="üåæ –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª–∏", command=self.train_models_dialog).pack(side=tk.LEFT, padx=5)
        ttk.Button(top_row, text="üîÑ –û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ", command=self.refresh_data).pack(side=tk.LEFT, padx=5)

        bottom_row = ttk.Frame(control_frame)
        bottom_row.pack(fill=tk.X, padx=10, pady=5)

        ttk.Button(bottom_row, text="üó∫Ô∏è –ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –≥—Ä–∞–Ω–∏—Ü—ã", command=self.show_all_borders).pack(side=tk.LEFT, padx=5)
        ttk.Button(bottom_row, text="üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", command=self.show_statistics).pack(side=tk.LEFT, padx=5)
        ttk.Button(bottom_row, text="üìç –¶–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç—É", command=self.center_map).pack(side=tk.LEFT, padx=5)
        ttk.Button(bottom_row, text="üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –∫–∞—Ä—Ç—É", command=self.clear_map).pack(side=tk.LEFT, padx=5)

    def create_main_content(self, parent):
        content_frame = ttk.Frame(parent)
        content_frame.pack(fill=tk.BOTH, expand=True, pady=10)

        map_frame = ttk.LabelFrame(content_frame, text="–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –∫–∞—Ä—Ç–∞ –†–æ—Å—Å–∏–∏")
        map_frame.pack(fill=tk.BOTH, expand=True, side=tk.LEFT, padx=(0, 5))

        self.map_handler = MapHandler(map_frame)
        self.map_handler.set_click_handler(self.on_map_click)

        self.load_borders_on_startup()

        info_frame = ttk.LabelFrame(content_frame, text="–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ")
        info_frame.pack(fill=tk.BOTH, expand=False, side=tk.RIGHT, padx=(5, 0), ipadx=10)

        self.create_info_panel(info_frame)

    def create_info_panel(self, parent):
        status_frame = ttk.LabelFrame(parent, text="–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã")
        status_frame.pack(fill=tk.X, pady=5)

        self.status_text = tk.Text(status_frame, height=8, width=40, bg=Config.COLORS['light'], wrap=tk.WORD,
                                   font=("Arial", 9))
        scrollbar = ttk.Scrollbar(status_frame, orient="vertical", command=self.status_text.yview)
        self.status_text.configure(yscrollcommand=scrollbar.set)

        self.status_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5, pady=5)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y, pady=5)

        quick_actions = ttk.LabelFrame(parent, text="–ë—ã—Å—Ç—Ä–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ")
        quick_actions.pack(fill=tk.X, pady=5)

        ttk.Button(quick_actions, text="üöÄ –ë—ã—Å—Ç—Ä—ã–π –ø—Ä–æ–≥–Ω–æ–∑", command=self.quick_prediction).pack(fill=tk.X, padx=5,
                                                                                                pady=2)
        ttk.Button(quick_actions, text="üìã –ò—Å—Ç–æ—Ä–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤", command=self.show_prediction_history).pack(fill=tk.X,
                                                                                                         padx=5, pady=2)

        self.region_info = ttk.LabelFrame(parent, text="–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–µ–≥–∏–æ–Ω–µ")
        self.region_info.pack(fill=tk.X, pady=5)

        self.region_label = ttk.Label(self.region_info, text="–†–µ–≥–∏–æ–Ω –Ω–µ –≤—ã–±—Ä–∞–Ω", font=("Arial", 10, "bold"))
        self.region_label.pack(padx=10, pady=10)

    def create_status_bar(self, parent):
        status_bar = ttk.Frame(parent)
        status_bar.pack(fill=tk.X, pady=5)

        status_label = ttk.Label(status_bar, textvariable=self.status_var, relief=tk.SUNKEN, anchor=tk.W)
        status_label.pack(fill=tk.X, padx=5, pady=2)

    def load_borders_on_startup(self):
        def load_task():
            self.update_status("üó∫Ô∏è –ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞–Ω–∏—Ü —Ä–µ–≥–∏–æ–Ω–æ–≤...")
            try:
                count = self.map_handler.load_regions_data()
                if count > 0:
                    self.borders_loaded = True
                    self.update_status(f"‚úÖ –ì—Ä–∞–Ω–∏—Ü—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {count} —Ä–µ–≥–∏–æ–Ω–æ–≤")
                else:
                    self.update_status("‚ö†Ô∏è –ì—Ä–∞–Ω–∏—Ü—ã –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∑–∞–≥—Ä—É–∑–∫—É –≤—Ä—É—á–Ω—É—é")
            except Exception as e:
                self.update_status(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≥—Ä–∞–Ω–∏—Ü: {e}")

        thread = threading.Thread(target=load_task)
        thread.daemon = True
        thread.start()

    def load_borders_dialog(self):
        filetypes = [
            ("JSON files", "*.json"),
            ("Text files", "*.txt"),
            ("All files", "*.*")
        ]

        filename = filedialog.askopenfilename(
            title="–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª —Å –≥—Ä–∞–Ω–∏—Ü–∞–º–∏ —Ä–µ–≥–∏–æ–Ω–æ–≤",
            filetypes=filetypes
        )

        if filename:
            self.update_status(f"üó∫Ô∏è –ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞–Ω–∏—Ü –∏–∑ {os.path.basename(filename)}...")
            try:
                count = self.map_handler.load_regions_data(filename)
                if count > 0:
                    self.borders_loaded = True
                    self.update_status(f"‚úÖ –ì—Ä–∞–Ω–∏—Ü—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {count} —Ä–µ–≥–∏–æ–Ω–æ–≤")
                    self.update_info(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã –≥—Ä–∞–Ω–∏—Ü—ã {count} —Ä–µ–≥–∏–æ–Ω–æ–≤\n\n"
                                     "–ì—Ä–∞–Ω–∏—Ü—ã –º–æ–∂–Ω–æ –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å —á–µ—Ä–µ–∑:\n"
                                     "'–ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –≥—Ä–∞–Ω–∏—Ü—ã' –∏–ª–∏\n"
                                     "–≤—ã–±—Ä–∞–≤ —Ä–µ–≥–∏–æ–Ω –Ω–∞ –∫–∞—Ä—Ç–µ")
                else:
                    self.update_status("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≥—Ä–∞–Ω–∏—Ü—ã")
            except Exception as e:
                self.update_status(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≥—Ä–∞–Ω–∏—Ü: {e}")

    def show_all_borders(self):
        if not self.borders_loaded:
            messagebox.showwarning("–í–Ω–∏–º–∞–Ω–∏–µ", "–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –≥—Ä–∞–Ω–∏—Ü—ã —Ä–µ–≥–∏–æ–Ω–æ–≤!")
            return

        self.map_handler.show_all_regions_borders()
        self.update_status("üó∫Ô∏è –û—Ç–æ–±—Ä–∞–∂–µ–Ω—ã –≥—Ä–∞–Ω–∏—Ü—ã –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤")

    def load_data_async(self):
        def load_task():
            self.update_status("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
            try:
                success = self.data_loader.load_all_data()
                self.data_loaded = success
                if success:
                    self.update_status("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
                    available_regions = self.data_loader.get_available_regions()
                    regions_info = "\n".join(available_regions[:10])
                    self.update_info(
                        f"–°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!\n\n–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–µ–≥–∏–æ–Ω—ã ({len(available_regions)}):\n{regions_info}" +
                        ("\n..." if len(available_regions) > 10 else "") +
                        "\n\n–î–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã:\n1. –í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–≥–∏–æ–Ω –Ω–∞ –∫–∞—Ä—Ç–µ\n2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–æ–≥–Ω–æ–∑–∞\n3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Ä–∞—Å—á–µ—Ç")
                else:
                    self.update_status("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
                    self.update_info(
                        "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ.\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ agricultural_data/")
            except Exception as e:
                self.update_status("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
                self.update_info(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö –∏ —Ñ–∞–π–ª—ã.")

        thread = threading.Thread(target=load_task)
        thread.daemon = True
        thread.start()

    def load_data_dialog(self):
        filetypes = [("Excel files", "*.xlsx"), ("Text files", "*.txt"), ("All files", "*.*")]
        filename = filedialog.askopenfilename(title="–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏", filetypes=filetypes)
        if filename:
            self.update_status(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ {os.path.basename(filename)}...")
            self.update_status("‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω")

    def train_models_dialog(self):
        if not self.data_loaded:
            messagebox.showwarning("–í–Ω–∏–º–∞–Ω–∏–µ", "–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ!")
            return

        self.update_status("üß† –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")

        all_X = None
        all_y = None
        regions = self.data_loader.get_available_regions()
        trained_regions = 0

        selected_regions = []

        weather_regions_count = 0
        for region in regions:
            region_data = self.data_loader.get_region_data(region)
            if region_data and region_data.get('weather') is not None:
                selected_regions.append(region)
                weather_regions_count += 1
                if weather_regions_count >= 3:
                    break

        for region in regions:
            if region not in selected_regions and len(selected_regions) < 5:
                region_data = self.data_loader.get_region_data(region)
                if region_data and region_data['yield'] is not None and len(region_data['yield']) > 3:
                    selected_regions.append(region)

        print(f"üéØ –†–µ–≥–∏–æ–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {selected_regions}")

        for region in selected_regions:
            try:
                region_data = self.data_loader.get_region_data(region)
                if region_data and region_data['yield'] is not None and len(region_data['yield']) > 3:
                    X, y = self.predictor.prepare_features(region_data)

                    if X is not None and not X.empty:
                        if all_X is None:
                            all_X = X
                            all_y = y
                        else:
                            all_X = pd.concat([all_X, X], ignore_index=True)
                            all_y = pd.concat([all_y, y], ignore_index=True)
                        trained_regions += 1

                        weather_status = "—Å –ø–æ–≥–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏" if region_data.get(
                            'weather') is not None else "–±–µ–∑ –ø–æ–≥–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
                        print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ —Ä–µ–≥–∏–æ–Ω–∞: {region} ({weather_status})")

                        if region_data.get('weather') is not None:
                            print(
                                f"   üìä –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–æ–≥–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {[col for col in X.columns if any(weather_term in col for weather_term in ['temp', 'pressure', 'humidity'])]}")

                        if region_data.get('mosbir_index') is not None and not region_data['mosbir_index'].empty:
                            print(
                                f"   üìà –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–Ω–¥–µ–∫—Å–∞ –ú–æ—Å–ë–∏—Ä–∂–∏: {[col for col in X.columns if 'mosbir' in col]}")
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–≥–∏–æ–Ω–∞ {region}: {e}")

        if all_X is not None and not all_X.empty:
            print(f"üìä –í—Å–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ: {len(all_X.columns)}")
            print(f"üìã –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {all_X.columns.tolist()}")

            weather_features = [col for col in all_X.columns if any(
                weather_term in col for weather_term in ['temp', 'pressure', 'humidity', 'spring', 'summer'])]
            print(f"üå§Ô∏è  –ü–æ–≥–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö: {weather_features}")

            mosbir_features = [col for col in all_X.columns if 'mosbir' in col]
            print(f"üìà –ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–Ω–¥–µ–∫—Å–∞ –ú–æ—Å–ë–∏—Ä–∂–∏ –≤ –¥–∞–Ω–Ω—ã—Ö: {mosbir_features}")

            success = self.predictor.train_models(all_X, all_y)
            if success:
                self.model_trained = True
                self.update_status("‚úÖ –ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω—ã")
                perf = self.predictor.get_model_performance()
                perf_text = "\n".join([f"{k}: R¬≤={v['r2']:.3f}, MAE={v['mae']:.3f}" for k, v in perf.items()])

                feature_importance = self.predictor.calculate_feature_importance(all_X, all_X.columns)
                if feature_importance:
                    top_features = "\n".join(
                        [f"- {feat}: {imp:.3f}" for feat, imp in list(feature_importance.items())[:5]])
                    importance_info = f"\n\n–¢–æ–ø-5 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:\n{top_features}"
                else:
                    importance_info = "\n\n–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"

                self.update_info(
                    f"–ú–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã –Ω–∞ {trained_regions} —Ä–µ–≥–∏–æ–Ω–∞—Ö\n\n–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π:\n{perf_text}{importance_info}")
            else:
                self.update_status("‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π")
                self.update_info("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö.")
        else:
            self.update_status("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            self.update_info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π.")

    def on_map_click(self, coords):
        lat, lon = coords

        marker = self.map_handler.add_marker(lat, lon, "–í—ã–±—Ä–∞–Ω–Ω–∞—è —Ç–æ—á–∫–∞")
        if marker is None:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –º–∞—Ä–∫–µ—Ä –Ω–∞ –∫–∞—Ä—Ç—É")
            return

        region_name = self.map_handler.find_region_by_coords(lat, lon)
        self.current_region = region_name

        if region_name:
            normalized_region = str(region_name).strip()
            self.region_label.config(text=normalized_region)

            if self.borders_loaded:
                self.map_handler.highlight_region(normalized_region)

            available_regions = self.data_loader.get_available_regions()

            region_found = False
            for available_region in available_regions:
                if (normalized_region.lower() in available_region.lower() or
                        available_region.lower() in normalized_region.lower()):
                    region_found = True
                    self.current_region = available_region
                    break

            if region_found:
                region_data = self.data_loader.get_region_data(self.current_region)
                weather_info = "–î–æ—Å—Ç—É–ø–Ω—ã ‚úì" if region_data and region_data.get('weather') is not None else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
                yield_info = "–î–æ—Å—Ç—É–ø–Ω—ã ‚úì" if region_data and not region_data['yield'].empty else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
                mosbir_info = "–î–æ—Å—Ç—É–ø–Ω—ã ‚úì" if region_data and region_data.get('mosbir_index') is not None and not \
                    region_data['mosbir_index'].empty else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"

                self.update_info(f"üìç –í—ã–±—Ä–∞–Ω —Ä–µ–≥–∏–æ–Ω: {self.current_region}\n\n"
                                 f"–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã: {lat:.4f}, {lon:.4f}\n"
                                 f"–ì—Ä–∞–Ω–∏—Ü—ã: {'–ó–∞–≥—Ä—É–∂–µ–Ω—ã ‚úì' if self.borders_loaded else '–ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã'}\n"
                                 f"–î–∞–Ω–Ω—ã–µ —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç–∏: {yield_info}\n"
                                 f"–ü–æ–≥–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {weather_info}\n"
                                 f"–ò–Ω–¥–µ–∫—Å –ú–æ—Å–ë–∏—Ä–∂–∏: {mosbir_info}\n"
                                 f"–ì–æ—Ç–æ–≤ –∫ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—é!")
            else:
                self.update_info(f"üìç –í—ã–±—Ä–∞–Ω —Ä–µ–≥–∏–æ–Ω: {normalized_region}\n\n"
                                 f"–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã: {lat:.4f}, {lon:.4f}\n"
                                 f"–ì—Ä–∞–Ω–∏—Ü—ã: {'–ó–∞–≥—Ä—É–∂–µ–Ω—ã ‚úì' if self.borders_loaded else '–ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã'}\n"
                                 f"‚ùå –î–∞–Ω–Ω—ã–µ —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã\n"
                                 f"–í—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥–æ–π —Ä–µ–≥–∏–æ–Ω")
        else:
            self.region_label.config(text="–†–µ–≥–∏–æ–Ω –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω")
            self.update_info("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–µ–≥–∏–æ–Ω.\n"
                             "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–±—Ä–∞—Ç—å —Ç–æ—á–∫—É –±–ª–∏–∂–µ\n–∫ —Ü–µ–Ω—Ç—Ä—É —Ä–µ–≥–∏–æ–Ω–∞ –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –≥—Ä–∞–Ω–∏—Ü—ã.")

    def quick_prediction(self):
        if not self.current_region:
            messagebox.showwarning("–í–Ω–∏–º–∞–Ω–∏–µ", "–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–≥–∏–æ–Ω –Ω–∞ –∫–∞—Ä—Ç–µ!")
            return
        if not self.model_trained:
            messagebox.showwarning("–í–Ω–∏–º–∞–Ω–∏–µ", "–°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª–∏!")
            return

        region_data = self.data_loader.get_region_data(self.current_region)
        if region_data is None or region_data['yield'] is None or region_data['yield'].empty:
            messagebox.showerror("–û—à–∏–±–∫–∞", f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö —É—Ä–æ–∂–∞–π–Ω–æ—Å—Ç–∏ –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞ {self.current_region}")
            return

        dialog = PredictionDialog(self.root, self.current_region, Config.CROPS)
        self.root.wait_window(dialog)
        if dialog.result:
            self.run_prediction(dialog.result)

    def run_prediction(self, parameters):
        self.update_status("üéØ –†–∞—Å—á–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞...")
        try:
            region_data = self.data_loader.get_region_data(self.current_region)
            if region_data is None or region_data['yield'] is None:
                messagebox.showerror("–û—à–∏–±–∫–∞", f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞ {self.current_region}")
                return

            X, y = self.predictor.prepare_features(region_data, lookback_period=parameters['history_years'])
            if X is None or X.empty:
                messagebox.showerror("–û—à–∏–±–∫–∞", "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞")
                return

            last_X = X.iloc[[-1]]
            prediction, confidence, deviation = self.predictor.predict(last_X, parameters['model'])
            if prediction is None:
                messagebox.showerror("–û—à–∏–±–∫–∞", "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑")
                return

            last_yield = region_data['yield']['yield'].iloc[-1] if len(region_data['yield']) > 0 else 0
            change = ((prediction - last_yield) / last_yield * 100) if last_yield > 0 else 0
            prediction_data = {
                'predicted_yield': prediction, 'confidence': confidence, 'deviation': deviation,
                'change': change, 'crop': parameters['crop'], 'period': parameters['period'],
                'model': parameters['model']
            }

            historical_data = {
                'years': region_data['yield']['year'].tolist(),
                'yields': region_data['yield']['yield'].tolist()
            }

            feature_importance = self.predictor.calculate_feature_importance(X, self.predictor.feature_names)
            ResultsWindow(self.root, self.current_region, prediction_data, historical_data, feature_importance)
            self.update_status("‚úÖ –ü—Ä–æ–≥–Ω–æ–∑ –≥–æ—Ç–æ–≤!")
        except Exception as e:
            messagebox.showerror("–û—à–∏–±–∫–∞", f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –ø—Ä–æ–≥–Ω–æ–∑–∞: {str(e)}")
            self.update_status("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è")

    def update_status(self, message):
        def safe_update():
            self.status_var.set(message)
            self.root.update_idletasks()

        self.root.after(0, safe_update)

    def update_info(self, message):
        def safe_update():
            self.status_text.config(state=tk.NORMAL)
            self.status_text.delete(1.0, tk.END)
            self.status_text.insert(tk.END, message)
            self.status_text.config(state=tk.DISABLED)

        self.root.after(0, safe_update)

    def refresh_data(self):
        self.load_data_async()

    def show_statistics(self):
        if self.data_loaded:
            stats = f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã:\n\n–†–µ–≥–∏–æ–Ω–æ–≤: {len(self.data_loader.yield_data['region'].unique())}\n"
            stats += f"–ì–æ—Ä–æ–¥–æ–≤ —Å –ø–æ–≥–æ–¥–æ–π: {len(self.data_loader.weather_data)}\n"
            stats += f"–ú–æ–¥–µ–ª–µ–π –æ–±—É—á–µ–Ω–æ: {len(self.predictor.models) if self.model_trained else 0}\n"
            stats += f"–ì—Ä–∞–Ω–∏—Ü—ã —Ä–µ–≥–∏–æ–Ω–æ–≤: {'–ó–∞–≥—Ä—É–∂–µ–Ω—ã' if self.borders_loaded else '–ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã'}\n"

            if self.data_loader.mosbir_index_data is not None and not self.data_loader.mosbir_index_data.empty:
                stats += f"–ó–∞–ø–∏—Å–µ–π –∏–Ω–¥–µ–∫—Å–∞ –ú–æ—Å–ë–∏—Ä–∂–∏: {len(self.data_loader.mosbir_index_data)}\n"
                min_date = self.data_loader.mosbir_index_data['date'].min()
                max_date = self.data_loader.mosbir_index_data['date'].max()
                stats += f"–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –∏–Ω–¥–µ–∫—Å–∞: {min_date.strftime('%d.%m.%Y')} - {max_date.strftime('%d.%m.%Y')}\n"

            if self.borders_loaded:
                stats += f"–†–µ–≥–∏–æ–Ω–æ–≤ —Å –≥—Ä–∞–Ω–∏—Ü–∞–º–∏: {len(self.map_handler.loaded_regions)}\n"

            if self.predictor.training_history:
                last_train = self.predictor.training_history[-1]
                stats += f"\n–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±—É—á–µ–Ω–∏–µ:\n"
                for model, score in last_train['performance'].items():
                    stats += f"- {model}: R¬≤={score['r2']:.3f}, MAE={score['mae']:.3f}\n"

            messagebox.showinfo("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", stats)
        else:
            messagebox.showwarning("–í–Ω–∏–º–∞–Ω–∏–µ", "–î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")

    def center_map(self):
        if self.map_handler:
            self.map_handler.center_on_russia()

    def clear_map(self):
        if self.map_handler:
            self.map_handler.clear_map()
            self.current_region = None
            self.region_label.config(text="–†–µ–≥–∏–æ–Ω –Ω–µ –≤—ã–±—Ä–∞–Ω")
            self.update_status("üóëÔ∏è –ö–∞—Ä—Ç–∞ –æ—á–∏—â–µ–Ω–∞")
            self.update_info("–ö–∞—Ä—Ç–∞ –æ—á–∏—â–µ–Ω–∞.\n–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–≤—ã–π —Ä–µ–≥–∏–æ–Ω –Ω–∞ –∫–∞—Ä—Ç–µ.")

    def show_prediction_history(self):
        messagebox.showinfo("–ò—Å—Ç–æ—Ä–∏—è", "–ò—Å—Ç–æ—Ä–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ")


def main():
    try:
        import tkintermapview
        import matplotlib.pyplot as plt
        import pandas as pd
        import sklearn
        import xgboost as xgb
        import lightgbm as lgb

        root = tk.Tk()
        app = AgriculturalPredictorApp(root)
        root.mainloop()

    except Exception as e:
        print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        messagebox.showerror("–û—à–∏–±–∫–∞", f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ: {e}")


if __name__ == "__main__":
    main()